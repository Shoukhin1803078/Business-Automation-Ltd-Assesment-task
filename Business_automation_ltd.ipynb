{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utUUS_ss-0Ao",
        "outputId": "d4d7734b-740f-45f1-fa53-6eb3f6915476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the dataset directory\n",
        "data_directory = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "# List the directories and a few files in each directory\n",
        "for root, dirs, files in os.walk(data_directory, top=1):\n",
        "    print(\"Root directory:\", root)\n",
        "    print(\"Subdirectories:\", dirs)\n",
        "    print(\"Files:\", files[:5])  # print first 5 files to avoid too much output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "1s06BgNQ-3Zc",
        "outputId": "7a5b32c1-1847-45de-bcfc-784324bb7165"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "walk() got multiple values for argument 'top'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3729b90bf89d>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# List the directories and a few files in each directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Root directory:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Subdirectories:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: walk() got multiple values for argument 'top'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the dataset directory\n",
        "data_directory = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "# List the directories and a few files in each directory\n",
        "for root, dirs, files in os.walk(data_directory):\n",
        "    print(\"Root directory:\", root)\n",
        "    print(\"Subdirectories:\", dirs)\n",
        "    print(\"Files:\", files[:5])  # print first 5 files to avoid too much output\n",
        "    if root != data_directory:\n",
        "        # To stop os.walk from going into subdirectories of the main directory\n",
        "        dirs[:] = []  # Clear the dirs list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBDHGcds_swl",
        "outputId": "dc00ef81-0d6b-460a-83e0-db175f9b933e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root directory: /content/drive/MyDrive/dataset\n",
            "Subdirectories: ['data', 'Resume']\n",
            "Files: []\n",
            "Root directory: /content/drive/MyDrive/dataset/data\n",
            "Subdirectories: ['data']\n",
            "Files: []\n",
            "Root directory: /content/drive/MyDrive/dataset/Resume\n",
            "Subdirectories: []\n",
            "Files: ['Resume.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the Resume.csv file\n",
        "csv_file_path = '/content/drive/MyDrive/dataset/Resume/Resume.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "resume_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(resume_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4dY-vvd_3Hr",
        "outputId": "bbbed06d-f0f5-4d2b-c769-0e7d51aa7813"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ID                                         Resume_str  \\\n",
            "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
            "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
            "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
            "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
            "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
            "\n",
            "                                         Resume_html Category  \n",
            "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
            "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
            "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
            "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
            "4  <div class=\"fontsize fontface vmargins hmargin...       HR  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize and convert to lower case\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words and word.isalnum()]\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "# Apply preprocessing to each resume text (assuming 'Resume_Text' is the column containing the text)\n",
        "resume_df['cleaned_text'] = resume_df['Resume_Text'].apply(preprocess_text)\n",
        "\n",
        "# Display the cleaned text\n",
        "print(resume_df['cleaned_text'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "zkqaqmuEAI0L",
        "outputId": "20d10b85-64b1-46bb-881c-62a92eb95ac3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Resume_Text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Resume_Text'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-928d6a1b3555>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Apply preprocessing to each resume text (assuming 'Resume_Text' is the column containing the text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mresume_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Resume_Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Display the cleaned text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Resume_Text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "resume_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the column names\n",
        "print(\"Column names in the CSV file:\", resume_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bysjjUd4AMAy",
        "outputId": "a304c92d-44c8-441a-d582-c79388c7728a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in the CSV file: ['ID', 'Resume_str', 'Resume_html', 'Category']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Path to the Resume.csv file\n",
        "csv_file_path = '/content/drive/MyDrive/dataset/Resume/Resume.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "resume_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize and convert to lower case\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words and word.isalnum()]\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "# Apply preprocessing to each resume text\n",
        "resume_df['cleaned_text'] = resume_df['Resume_str'].apply(preprocess_text)\n",
        "\n",
        "# Display the cleaned text\n",
        "print(resume_df['cleaned_text'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ur7oX1YAXJy",
        "outputId": "72fa323c-7746-46e7-c18e-66e7f40809b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    hr associate hr administrator summary dedicate...\n",
            "1    hr specialist us hr operations summary versati...\n",
            "2    hr director summary 20 years experience recrui...\n",
            "3    hr specialist summary dedicated driven dynamic...\n",
            "4    hr manager skill highlights hr skills hr depar...\n",
            "Name: cleaned_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Extracting features using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(resume_df['cleaned_text'])\n",
        "y = resume_df['Category']  # Use the 'Category' column for labels\n",
        "\n",
        "# Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a RandomForest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYKd9dA4Alpy",
        "outputId": "113a5f50-a832-4f3e-e616-2cd3e4980764"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            ACCOUNTANT       0.81      0.95      0.88        37\n",
            "              ADVOCATE       0.86      0.84      0.85        37\n",
            "           AGRICULTURE       0.25      0.07      0.11        15\n",
            "               APPAREL       0.33      0.14      0.20        29\n",
            "                  ARTS       0.31      0.17      0.22        29\n",
            "            AUTOMOBILE       0.00      0.00      0.00        11\n",
            "              AVIATION       0.82      0.91      0.86        35\n",
            "               BANKING       0.62      0.69      0.66        29\n",
            "                   BPO       0.00      0.00      0.00         4\n",
            "  BUSINESS-DEVELOPMENT       0.68      0.60      0.64        35\n",
            "                  CHEF       0.85      0.82      0.84        40\n",
            "          CONSTRUCTION       0.91      0.91      0.91        43\n",
            "            CONSULTANT       0.76      0.48      0.59        33\n",
            "              DESIGNER       0.88      0.85      0.86        33\n",
            "         DIGITAL-MEDIA       0.70      0.74      0.72        35\n",
            "           ENGINEERING       0.57      0.80      0.67        30\n",
            "               FINANCE       0.75      0.69      0.72        35\n",
            "               FITNESS       0.74      0.74      0.74        35\n",
            "            HEALTHCARE       0.57      0.67      0.62        30\n",
            "                    HR       0.67      0.96      0.79        25\n",
            "INFORMATION-TECHNOLOGY       0.59      0.88      0.71        43\n",
            "      PUBLIC-RELATIONS       0.68      0.58      0.62        26\n",
            "                 SALES       0.46      0.57      0.51        42\n",
            "               TEACHER       0.63      0.77      0.69        35\n",
            "\n",
            "              accuracy                           0.69       746\n",
            "             macro avg       0.60      0.62      0.60       746\n",
            "          weighted avg       0.66      0.69      0.67       746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predictions, zero_division=0))  # Handling undefined metric warning by setting zero_division to 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeP06ookAwcr",
        "outputId": "1cabcc53-01e3-4fbd-a635-32cc9bb79461"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            ACCOUNTANT       0.81      0.95      0.88        37\n",
            "              ADVOCATE       0.86      0.84      0.85        37\n",
            "           AGRICULTURE       0.25      0.07      0.11        15\n",
            "               APPAREL       0.33      0.14      0.20        29\n",
            "                  ARTS       0.31      0.17      0.22        29\n",
            "            AUTOMOBILE       0.00      0.00      0.00        11\n",
            "              AVIATION       0.82      0.91      0.86        35\n",
            "               BANKING       0.62      0.69      0.66        29\n",
            "                   BPO       0.00      0.00      0.00         4\n",
            "  BUSINESS-DEVELOPMENT       0.68      0.60      0.64        35\n",
            "                  CHEF       0.85      0.82      0.84        40\n",
            "          CONSTRUCTION       0.91      0.91      0.91        43\n",
            "            CONSULTANT       0.76      0.48      0.59        33\n",
            "              DESIGNER       0.88      0.85      0.86        33\n",
            "         DIGITAL-MEDIA       0.70      0.74      0.72        35\n",
            "           ENGINEERING       0.57      0.80      0.67        30\n",
            "               FINANCE       0.75      0.69      0.72        35\n",
            "               FITNESS       0.74      0.74      0.74        35\n",
            "            HEALTHCARE       0.57      0.67      0.62        30\n",
            "                    HR       0.67      0.96      0.79        25\n",
            "INFORMATION-TECHNOLOGY       0.59      0.88      0.71        43\n",
            "      PUBLIC-RELATIONS       0.68      0.58      0.62        26\n",
            "                 SALES       0.46      0.57      0.51        42\n",
            "               TEACHER       0.63      0.77      0.69        35\n",
            "\n",
            "              accuracy                           0.69       746\n",
            "             macro avg       0.60      0.62      0.60       746\n",
            "          weighted avg       0.66      0.69      0.67       746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming `predictions` is your model's output on X_test and `X_test` was created from `resume_df` with a train_test_split\n",
        "# Retrieve the original indices of your test set resumes\n",
        "test_indices = X_test.index\n",
        "\n",
        "# Create a DataFrame with IDs and their predicted categories\n",
        "results_df = pd.DataFrame({\n",
        "    'ID': resume_df.loc[test_indices, 'ID'],  # Assuming 'ID' is the identifier column in your original DataFrame\n",
        "    'Category': predictions\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv('/content/drive/MyDrive/dataset/categorized_resumes.csv', index=False)\n",
        "\n",
        "print(\"Sample output CSV file created and saved!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "Cmz9Dy0zBDC7",
        "outputId": "751eb8d0-4bb3-4705-d2bb-78be0488b9e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'csr_matrix' object has no attribute 'index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-76d1eebf36df>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assuming `predictions` is your model's output on X_test and `X_test` was created from `resume_df` with a train_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Retrieve the original indices of your test set resumes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create a DataFrame with IDs and their predicted categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'csr_matrix' object has no attribute 'index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming resume_df['cleaned_text'] is your preprocessed text column\n",
        "# Splitting the data into training and testing sets while preserving the DataFrame structure\n",
        "train_df, test_df = train_test_split(resume_df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Extract features\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train = vectorizer.fit_transform(train_df['cleaned_text'])\n",
        "X_test = vectorizer.transform(test_df['cleaned_text'])\n",
        "y_train = train_df['Category']\n",
        "y_test = test_df['Category']\n"
      ],
      "metadata": {
        "id": "TsVl3nnTG1St"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Training a RandomForest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Creating a DataFrame to match IDs with their predicted categories\n",
        "results_df = pd.DataFrame({\n",
        "    'ID': test_df['ID'],  # 'ID' column from test_df\n",
        "    'Category': predictions\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv('/content/drive/MyDrive/dataset/categorized_resumes.csv', index=False)\n",
        "print(\"Sample output CSV file created and saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR88s9bCHF70",
        "outputId": "1ca19559-b81b-4cf0-fd74-7cbcdf3d1e3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample output CSV file created and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Path to the file you want to download\n",
        "file_path = '/content/drive/MyDrive/dataset/categorized_resumes.csv'\n",
        "\n",
        "# Trigger the download\n",
        "files.download(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zYdlaJS7HKRM",
        "outputId": "98238160-54f8-4426-f412-b7a7e394457a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb3c9c10-ae57-43cf-932c-834700e0dc2b\", \"categorized_resumes.csv\", 14826)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awJhVKcZIAaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}